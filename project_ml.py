# -*- coding: utf-8 -*-
"""PROJECT_ML.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dnYep5bsvzjuoEj0vWNldfb0DWg5b6Bn

#PROJECT:
#**TRAINING DATASET OF GESTURE PHASE SEGMENTATION WITH TECHNIQUES OF CLASSIFICATION AND CLUSTERING**

**IMPORTING REQUIRED DATASET:**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
df=pd.read_csv("/content/drive/MyDrive/gesture+phase+segmentation/a1_processtrain2.csv")
df

df1=pd.read_csv("/content/drive/MyDrive/gesture+phase+segmentation/a1_processTest.csv")
df1

"""**CHECKING DATA INFO:**"""

df.info()
df1.info()

"""**CHECK FOR MISSING VALUES:**"""

df.isna().sum()
df1.isna().sum()

"""**REPLACING CATEGORICAL TEXT DATA WITH NUMERICAL DATA FOR PURPOSE OF CLASSIFICATION:**"""

df1['Phase'].replace(['D','P','R','S','H'],[0,1,2,3,4],inplace=True)
df1

"""**TRAINING MODEL AND DEFINING TEST VARIABLES:**"""

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(df,df1,test_size=0.3,random_state=25)

"""**CLASSIFICATION:**

**METHOD 1:LOGISTIC REGRESSION**
"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix
Lr=LogisticRegression(penalty='l2',tol=0.01,C=10.0,max_iter=10000)
Lr.fit(x_train,np.ravel(y_train,order='C'))
pred=Lr.predict(x_test)
from sklearn.metrics import accuracy_score
#acc=accuracy_score(pred,y_test)
acc=accuracy_score(pred,y_test)
print(acc)
cm=confusion_matrix(y_test,pred)
sns.heatmap(cm,annot=True,cbar=False,cmap='summer')

"""**METHOD 2: SVC**"""

from sklearn.svm import SVC
sv=SVC(C=85.0,kernel='rbf')
sv.fit(x_train,np.ravel(y_train,order='C'))
pred=sv.predict(x_test)
from sklearn.metrics import accuracy_score
acc1=accuracy_score(pred,y_test)
acc1

"""**METHOD 3:DECISION TREE**"""

from sklearn.tree import DecisionTreeClassifier
Dt=DecisionTreeClassifier(criterion='gini',splitter='best',max_depth=5)
Dt.fit(x_train,np.ravel(y_train,order='C'))
pred=Dt.predict(x_test)
from sklearn.metrics import accuracy_score
acc2=accuracy_score(pred,y_test)
acc2

"""**METHOD 4: NAIVE BAYES(GAUSSIAN NB)**"""

from sklearn.naive_bayes import GaussianNB
gnb=GaussianNB()
gnb.fit(x_train,np.ravel(y_train,order='C'))
pred=gnb.predict(x_test)
from sklearn.metrics import accuracy_score
acc3=accuracy_score(pred,y_test)
acc3

"""**METHOD 5: K NEIGBORS CLASSIFIER USING RANDOM FOREST CLASSIFIER, EXTRA TREES CLASSIFIER AND BAGGING CLASSIFIER:**"""

from sklearn.neighbors import KNeighborsClassifier
knn=KNeighborsClassifier()
from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier,BaggingClassifier
clf1=RandomForestClassifier(n_estimators=100,criterion='gini',max_depth=5)
clf2=ExtraTreesClassifier(n_estimators=100,criterion='gini',max_depth=5)
clf3=BaggingClassifier(n_estimators=10,max_samples=1.0,max_features=1.0,
                      bootstrap=True) #base_estimator=knn
clf=[clf1,clf2,clf3]
clf_name=['RF','ET','BAG']
for model,model_name in zip(clf,clf_name):
  model.fit(x_train,y_train)
  pred=model.predict(x_test)
  acc=accuracy_score(pred,y_test)
  print(acc)

train_scores = []
test_scores = []
n_esti = np.arange(1, 1000, 100)
ron_cls = RandomForestClassifier(criterion='gini', random_state = 0)
for i in n_esti:
    ron_cls.set_params(n_estimators = i)
    ron_cls.fit(x_train,y_train)
    train_scores.append(ron_cls.score(x_train,np.ravel(y_train,order='C')))
    test_scores.append(ron_cls.score(x_test,y_test))

from sklearn.metrics import classification_report
cr=classification_report(y_test,pred)
print(cr)

"""**CLUSTERING:**

**METHOD 1: K MEANS CLUSTERING**
"""

from sklearn.cluster import KMeans
kmeans = KMeans(n_clusters=5)
kmeans.fit(x_train,np.ravel(y_train,order='C'))
pred=kmeans.predict(x_test)
from sklearn.metrics import accuracy_score
acc3=accuracy_score(pred,y_test)
acc3

"""**PREPARED BY:**
**SHAURYA KUSHWAH**


"""

